For the evaluation of model-based quantities, we use Mohn's rho ($\rho_M$ \toshi{$\rho_{Mr}$?}, equation \ref{eqn:mohn}) and a modified version ($\rho_{Mr}$ \toshi{$\rho_{p}$?}, equation \ref{eqn:mohn2}). 
\toshi{IF my understanding above on $\rho_{p}$ is correct, this is also for assessing prediction skill but "model based". I think we can highlight here difference in model-based and model-free in addition to model validation with/without prediction.}

We used the mean absolute scaled error (MASE, equation \ref{eqn:mase}) to evaluate prediction skill. The best statistical measure to use depends, however, on the objectives of the analysis and using more than one measure can be helpful in providing insight into the nature of observation and process error structures \parencite{kell2016xval}. Therefore we also use root mean squared error ($E^{\prime 2}$, equation \ref{eqn:rmse}), correlation ($\rho$) and the standard deviation ($\sigma$). 

$E^\prime$ is a commonly used metric, as the square root of a variance it can also be interpreted as the standard deviation of the unexplained variance,  lower values indicate better fits. $E^\prime$ is sensitive to outliers, however,and favours forecasts that avoid large deviations from the mean and cannot be used to compare across series. The correlation ($\rho$) in contrast is unaffected by the amplitude of the variations, insensitive to biases and errors in variance, and can be used to compare across series. $E^{\prime 2}$ and $\rho$ are related by the cosine rule i.e.

 \begin{equation} 
 E^{\prime 2} = \sigma_o^2 + \sigma_f^2 - 2\sigma_o\sigma_f\rho
 \end{equation}

Where the reference set ($o$) are the observations not included in the retrospective assessment and the values ($f$) are their estimates. 
 
This means that $E^\prime$, $\rho$ and $\sigma_f$ can be summarised simultaneously in a single diagram\parencite{taylor2001summarizing} providing a concise statistical summary of how well patterns match each other and are therefore especially useful for evaluating multiple aspects or in gauging the relative skill of different models \parencite{griggs2002climate}.
