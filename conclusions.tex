\section{Conclusions}

What we conclude
\begin{itemize}
    \item In fisheries unlike other fields we try to account for the past but not for the future. Here we propose a way to assess model predictive performance and to account for alternative models within a common diagnostic framework.
    \item  MASE allows alternative model structures and datasets to be compared. Also by looking at predictions we are avoiding overfitting .
    \item Consequences for stock assessment benchmarking
    \item Consequences for uncertainty, risk and MSE.
    \item Next steps
\item \red{I think we should expand the discussion and integrate the results from the cookbook into it, which I think fit very well here. My impression here is that we say that a model with a good MASE is indeed a good model and this is suffice as diagnostics. I think we should go beyond this concept and says that models validation needs to be seen in a more holistic perspective and that multiple diagnostics should be used as they provide the instruments to discover different symptoms linked to different issue with the model, from model mis-specification, to data conflicts, to data issue etc. }
\end{itemize}

